{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58a1b640-d254-46c3-8765-dfd38eea187d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing real: 100%|███████████████████████████████████████████████████████████| 3397/3397 [1:19:00<00:00,  1.40s/it]\n",
      "Processing fake: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 4206/4206 [1:32:51<00:00,  1.32s/it]\n",
      "Processing .ipynb_checkpoints: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "from moviepy.editor import VideoFileClip\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Parameters\n",
    "clip_len = 150\n",
    "lip_landmark_ids = list(range(61, 81))  # 20 lip landmarks\n",
    "\n",
    "# Initialize Mediapipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1)\n",
    "\n",
    "# Input/output\n",
    "input_root = \"dataset\"\n",
    "output_root = \"processed_dataset\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "def extract_audio_from_video(video_path, temp_wav_path):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path)\n",
    "        clip.audio.write_audiofile(temp_wav_path, verbose=False, logger=None)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def extract_lip_landmarks_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    landmarks = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            face = results.multi_face_landmarks[0]\n",
    "            points = [(lmk.x, lmk.y) for i, lmk in enumerate(face.landmark) if i in lip_landmark_ids]\n",
    "            landmarks.append(points)\n",
    "\n",
    "    cap.release()\n",
    "    return np.array(landmarks)  # shape: (T, 20, 2)\n",
    "\n",
    "def extract_mfcc(temp_wav_path, fps, total_frames):\n",
    "    try:\n",
    "        y, sr = librosa.load(temp_wav_path, sr=None)\n",
    "        duration = total_frames / fps\n",
    "        y = y[:int(sr * duration)]\n",
    "\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        mfcc = mfcc.T  # shape (n_frames, 13)\n",
    "\n",
    "        # Align MFCC to video FPS using linear interpolation\n",
    "        indices = np.linspace(0, len(mfcc) - 1, total_frames).astype(int)\n",
    "        mfcc_aligned = mfcc[indices]\n",
    "        return mfcc_aligned  # shape: (total_frames, 13)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Process each class\n",
    "for cls in os.listdir(input_root):\n",
    "    class_path = os.path.join(input_root, cls)\n",
    "    if not os.path.isdir(class_path): continue\n",
    "\n",
    "    out_frame_dir = os.path.join(output_root, cls, \"frames\")\n",
    "    out_audio_dir = os.path.join(output_root, cls, \"audio_features\")\n",
    "    os.makedirs(out_frame_dir, exist_ok=True)\n",
    "    os.makedirs(out_audio_dir, exist_ok=True)\n",
    "\n",
    "    for filename in tqdm(os.listdir(class_path), desc=f\"Processing {cls}\"):\n",
    "        if not filename.endswith(\".mp4\"):\n",
    "            continue\n",
    "\n",
    "        vid_path = os.path.join(class_path, filename)\n",
    "        temp_wav_path = \"temp.wav\"\n",
    "        name_base = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Extract landmarks\n",
    "        frames = extract_lip_landmarks_from_video(vid_path)\n",
    "        if len(frames) < clip_len:\n",
    "            # print(f\"[SKIP] {filename} has only {len(frames)} frames.\")\n",
    "            continue\n",
    "\n",
    "        # Extract aligned audio\n",
    "        success = extract_audio_from_video(vid_path, temp_wav_path)\n",
    "        if not success:\n",
    "            print(f\"[ERROR] Audio extract error in {filename}\")\n",
    "            continue\n",
    "\n",
    "        fps = cv2.VideoCapture(vid_path).get(cv2.CAP_PROP_FPS)\n",
    "        mfcc_full = extract_mfcc(temp_wav_path, fps, len(frames))\n",
    "        if mfcc_full is None or mfcc_full.shape[0] < clip_len:\n",
    "            print(f\"[ERROR] MFCC extraction error in {filename}\")\n",
    "            continue\n",
    "\n",
    "        # Save first valid clip of 150 frames\n",
    "        lip_clip = frames[:clip_len]\n",
    "        mfcc_clip = mfcc_full[:clip_len]\n",
    "\n",
    "        # Save\n",
    "        np.save(os.path.join(out_frame_dir, f\"{name_base}_clip0_frame.npy\"), lip_clip)\n",
    "        np.save(os.path.join(out_audio_dir, f\"{name_base}_clip0_af.npy\"), mfcc_clip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8ffc478-9421-487d-8b0d-db5ba0defef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LipSyncDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.root_dir = root_dir\n",
    "        classes = {'real': 0, 'fake': 1}\n",
    "        \n",
    "        for cls in classes:\n",
    "            frame_dir = os.path.join(root_dir, cls, 'frames')\n",
    "            audio_dir = os.path.join(root_dir, cls, 'audio_features')\n",
    "            \n",
    "            for fname in os.listdir(frame_dir):\n",
    "                if not fname.endswith(\"_clip0_frame.npy\"):\n",
    "                    continue\n",
    "                base = fname.replace(\"_clip0_frame.npy\", \"\")\n",
    "                frame_path = os.path.join(frame_dir, fname)\n",
    "                audio_path = os.path.join(audio_dir, f\"{base}_clip0_af.npy\")\n",
    "                \n",
    "                if os.path.exists(audio_path):\n",
    "                    self.data.append((frame_path, audio_path))\n",
    "                    self.labels.append(classes[cls])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_path, audio_path = self.data[idx]\n",
    "        frames = np.load(frame_path)              # (150, 20, 2)\n",
    "        audio = np.load(audio_path)               # (150, 13)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # To tensors\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)  # (150, 20, 2)\n",
    "        audio = torch.tensor(audio, dtype=torch.float32)    # (150, 13)\n",
    "        return frames, audio, torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db8fa269-8f71-41f4-a559-12408e654e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 1: Loss = 130.6889, Accuracy = 0.5458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 39.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 1: Loss = 32.7551, Accuracy = 0.5639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:13<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 2: Loss = 130.2756, Accuracy = 0.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 2: Loss = 32.5948, Accuracy = 0.5731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:14<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 3: Loss = 129.4233, Accuracy = 0.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 39.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 3: Loss = 32.5132, Accuracy = 0.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:13<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 4: Loss = 127.9113, Accuracy = 0.5844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 4: Loss = 32.1936, Accuracy = 0.5863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:13<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 5: Loss = 126.7912, Accuracy = 0.5917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 5: Loss = 31.8930, Accuracy = 0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 6: Loss = 125.0035, Accuracy = 0.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 6: Loss = 31.4754, Accuracy = 0.6140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 7: Loss = 122.2092, Accuracy = 0.6326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 7: Loss = 30.8193, Accuracy = 0.6232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 8: Loss = 120.0324, Accuracy = 0.6431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 8: Loss = 30.1078, Accuracy = 0.6430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Training: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 9: Loss = 117.0254, Accuracy = 0.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 - Validation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 39.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 9: Loss = 29.3758, Accuracy = 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 10: Loss = 114.9988, Accuracy = 0.6577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 10: Loss = 29.1156, Accuracy = 0.6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 11: Loss = 113.0194, Accuracy = 0.6692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 11: Loss = 28.6125, Accuracy = 0.6746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 12: Loss = 111.2083, Accuracy = 0.6748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 12: Loss = 28.4791, Accuracy = 0.6640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 13: Loss = 108.2865, Accuracy = 0.6903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 13: Loss = 28.1062, Accuracy = 0.6719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 14: Loss = 107.1535, Accuracy = 0.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 14: Loss = 27.6888, Accuracy = 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 15: Loss = 104.8345, Accuracy = 0.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 15: Loss = 27.2032, Accuracy = 0.6733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 16: Loss = 103.1308, Accuracy = 0.7094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 16: Loss = 27.0400, Accuracy = 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 17: Loss = 100.1368, Accuracy = 0.7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 17: Loss = 26.9736, Accuracy = 0.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 18: Loss = 98.5429, Accuracy = 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 18: Loss = 26.4237, Accuracy = 0.6838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 19: Loss = 99.5320, Accuracy = 0.7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 35.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 19: Loss = 26.7182, Accuracy = 0.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:12<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 20: Loss = 98.7577, Accuracy = 0.7266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 20: Loss = 26.9901, Accuracy = 0.6904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 21: Loss = 96.0934, Accuracy = 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 21: Loss = 25.7416, Accuracy = 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 22: Loss = 94.2535, Accuracy = 0.7421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 22: Loss = 25.6873, Accuracy = 0.7022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 23: Loss = 92.2767, Accuracy = 0.7507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 38.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 23: Loss = 25.1484, Accuracy = 0.7088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 24: Loss = 91.7756, Accuracy = 0.7556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 24: Loss = 25.3549, Accuracy = 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 25: Loss = 90.6486, Accuracy = 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 25: Loss = 25.2351, Accuracy = 0.7101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 26: Loss = 87.2860, Accuracy = 0.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 26: Loss = 25.0900, Accuracy = 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 27: Loss = 87.4194, Accuracy = 0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 27: Loss = 25.0960, Accuracy = 0.7141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 28: Loss = 85.6841, Accuracy = 0.7754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 28: Loss = 25.1850, Accuracy = 0.7128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 29: Loss = 85.6028, Accuracy = 0.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 29: Loss = 25.0256, Accuracy = 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 30: Loss = 84.1859, Accuracy = 0.7810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 30: Loss = 24.5538, Accuracy = 0.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 31: Loss = 82.5587, Accuracy = 0.7929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 31: Loss = 24.5013, Accuracy = 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 32: Loss = 82.5557, Accuracy = 0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 32: Loss = 24.3057, Accuracy = 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 33: Loss = 81.1588, Accuracy = 0.7952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 33: Loss = 24.6324, Accuracy = 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 34: Loss = 80.2687, Accuracy = 0.7939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 34: Loss = 24.1994, Accuracy = 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 35: Loss = 79.3391, Accuracy = 0.7968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 35: Loss = 24.4181, Accuracy = 0.7404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 36: Loss = 77.6535, Accuracy = 0.8018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 36: Loss = 24.2245, Accuracy = 0.7444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 37: Loss = 79.1598, Accuracy = 0.8005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 43.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 37: Loss = 24.5593, Accuracy = 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 38: Loss = 81.7618, Accuracy = 0.7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 38: Loss = 24.9047, Accuracy = 0.7431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 39: Loss = 77.3703, Accuracy = 0.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 38.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 39: Loss = 23.8789, Accuracy = 0.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 40: Loss = 75.7309, Accuracy = 0.8150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 40: Loss = 24.1401, Accuracy = 0.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 41: Loss = 74.0006, Accuracy = 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 41: Loss = 23.6502, Accuracy = 0.7470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 42: Loss = 72.5308, Accuracy = 0.8186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 42: Loss = 23.7119, Accuracy = 0.7444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 43: Loss = 72.9567, Accuracy = 0.8203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 43: Loss = 23.7509, Accuracy = 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 44: Loss = 72.4795, Accuracy = 0.8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 44: Loss = 23.6898, Accuracy = 0.7576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 45: Loss = 71.0809, Accuracy = 0.8216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 45: Loss = 23.9328, Accuracy = 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 46: Loss = 71.2485, Accuracy = 0.8262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 46: Loss = 23.8584, Accuracy = 0.7549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 47: Loss = 70.4717, Accuracy = 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 40.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 47: Loss = 23.7226, Accuracy = 0.7589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 48: Loss = 70.2881, Accuracy = 0.8265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 41.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 48: Loss = 23.7904, Accuracy = 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 49: Loss = 69.3722, Accuracy = 0.8285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 42.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 49: Loss = 23.8594, Accuracy = 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Training: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 190/190 [00:11<00:00, 16.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Epoch 50: Loss = 69.2596, Accuracy = 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 48/48 [00:01<00:00, 37.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val]   Epoch 50: Loss = 23.3876, Accuracy = 0.7694\n",
      "Model saved as lipsync_deepfake_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =====================\n",
    "# Dataset Loader\n",
    "# =====================\n",
    "class LipSyncDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.root_dir = root_dir\n",
    "        classes = {'real': 0, 'fake': 1}\n",
    "        \n",
    "        for cls in classes:\n",
    "            frame_dir = os.path.join(root_dir, cls, 'frames')\n",
    "            audio_dir = os.path.join(root_dir, cls, 'audio_features')\n",
    "            \n",
    "            for fname in os.listdir(frame_dir):\n",
    "                if not fname.endswith(\"_clip0_frame.npy\"):\n",
    "                    continue\n",
    "                base = fname.replace(\"_clip0_frame.npy\", \"\")\n",
    "                frame_path = os.path.join(frame_dir, fname)\n",
    "                audio_path = os.path.join(audio_dir, f\"{base}_clip0_af.npy\")\n",
    "                \n",
    "                if os.path.exists(audio_path):\n",
    "                    self.data.append((frame_path, audio_path))\n",
    "                    self.labels.append(classes[cls])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_path, audio_path = self.data[idx]\n",
    "        frames = np.load(frame_path)              # (150, 20, 2)\n",
    "        audio = np.load(audio_path)               # (150, 13)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)  # (150, 20, 2)\n",
    "        audio = torch.tensor(audio, dtype=torch.float32)    # (150, 13)\n",
    "        return frames, audio, torch.tensor(label)\n",
    "\n",
    "# =====================\n",
    "# Model Definition\n",
    "# =====================\n",
    "class LipSyncLSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Lip branch\n",
    "        self.lip_lstm = nn.LSTM(input_size=40, hidden_size=64, batch_first=True)\n",
    "\n",
    "        # Audio branch\n",
    "        self.audio_lstm = nn.LSTM(input_size=13, hidden_size=64, batch_first=True)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 2)  # Real or Fake\n",
    "        )\n",
    "\n",
    "    def forward(self, lips, audio):\n",
    "        B = lips.shape[0]\n",
    "        lips = lips.view(B, 150, -1)  # (B, 150, 40)\n",
    "\n",
    "        _, (h_lip, _) = self.lip_lstm(lips)      # (1, B, 64)\n",
    "        _, (h_audio, _) = self.audio_lstm(audio) # (1, B, 64)\n",
    "\n",
    "        fused = torch.cat([h_lip[-1], h_audio[-1]], dim=1)  # (B, 128)\n",
    "        return self.fc(fused)\n",
    "\n",
    "# =====================\n",
    "# Training Setup\n",
    "# =====================\n",
    "def train_model():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    dataset = LipSyncDataset(\"processed_dataset\")\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=16)\n",
    "\n",
    "    model = LipSyncLSTMClassifier().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        for lips, audio, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            lips, audio, labels = lips.to(device), audio.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(lips, audio)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_acc = train_correct / len(train_set)\n",
    "        print(f\"[Train] Epoch {epoch+1}: Loss = {running_loss:.4f}, Accuracy = {train_acc:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for lips, audio, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                lips, audio, labels = lips.to(device), audio.to(device), labels.to(device)\n",
    "                outputs = model(lips, audio)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        val_acc = val_correct / len(val_set)\n",
    "        print(f\"[Val]   Epoch {epoch+1}: Loss = {val_loss:.4f}, Accuracy = {val_acc:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), \"lipsync_deepfake_model.pth\")\n",
    "    print(\"Model saved as lipsync_deepfake_model.pth\")\n",
    "\n",
    "# Run training\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6639689-f591-4c1b-9613-e59ab984ebd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Audio extract failed: 'NoneType' object has no attribute 'write_audiofile'\n",
      "Prediction: FAKE (Confidence: 1.00)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "from moviepy.editor import VideoFileClip\n",
    "import mediapipe as mp\n",
    "\n",
    "# ------------------------------\n",
    "# Define model again (should match training)\n",
    "# ------------------------------\n",
    "class LipSyncLSTMClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Lip branch\n",
    "        self.lip_lstm = nn.LSTM(input_size=40, hidden_size=64, batch_first=True)\n",
    "\n",
    "        # Audio branch\n",
    "        self.audio_lstm = nn.LSTM(input_size=13, hidden_size=64, batch_first=True)\n",
    "\n",
    "        # Classifier\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 2)  # Real or Fake\n",
    "        )\n",
    "\n",
    "    def forward(self, lips, audio):\n",
    "        B = lips.shape[0]\n",
    "        lips = lips.view(B, 150, -1)  # (B, 150, 40)\n",
    "\n",
    "        _, (h_lip, _) = self.lip_lstm(lips)      # (1, B, 64)\n",
    "        _, (h_audio, _) = self.audio_lstm(audio) # (1, B, 64)\n",
    "\n",
    "        fused = torch.cat([h_lip[-1], h_audio[-1]], dim=1)  # (B, 128)\n",
    "        return self.fc(fused)\n",
    "\n",
    "# ------------------------------\n",
    "# Load trained model weights\n",
    "# ------------------------------\n",
    "model = LipSyncLSTMClassifier()\n",
    "model.load_state_dict(torch.load(\"lipsync_deepfake_model.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# ------------------------------\n",
    "# MediaPipe for lip landmarks\n",
    "# ------------------------------\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "lip_landmarks = list(range(61, 81))  # 20 lip landmarks\n",
    "\n",
    "def extract_lip_landmarks(video_path, max_frames=150):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    lips = []\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1) as face_mesh:\n",
    "        while len(lips) < max_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(rgb)\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    points = []\n",
    "                    for idx in lip_landmarks:\n",
    "                        lm = face_landmarks.landmark[idx]\n",
    "                        points.extend([lm.x, lm.y])  # 2 values per landmark\n",
    "                    lips.append(points)\n",
    "                    break\n",
    "        cap.release()\n",
    "\n",
    "    lips = np.array(lips)\n",
    "    if len(lips) < max_frames:\n",
    "        pad = np.zeros((max_frames - len(lips), 40))\n",
    "        lips = np.vstack([lips, pad])\n",
    "    else:\n",
    "        lips = lips[:max_frames]\n",
    "    return lips  # shape [150, 40]\n",
    "\n",
    "# ------------------------------\n",
    "# Extract audio features (MFCC)\n",
    "# ------------------------------\n",
    "def extract_audio_from_video(video_path, temp_wav_path=\"temp.wav\"):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path)\n",
    "        clip.audio.write_audiofile(temp_wav_path, verbose=False, logger=None)\n",
    "        return temp_wav_path\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Audio extract failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_audio_features(video_path, max_frames=150):\n",
    "    temp_wav_path = extract_audio_from_video(video_path)\n",
    "    if temp_wav_path is None:\n",
    "        return np.zeros((max_frames, 13))  # Adjusted for n_mfcc=13\n",
    "\n",
    "    y, sr = librosa.load(temp_wav_path, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # ✅ correct number of MFCCs\n",
    "    mfcc = mfcc.T  # [T, 13]\n",
    "\n",
    "    if len(mfcc) < max_frames:\n",
    "        pad = np.zeros((max_frames - len(mfcc), 13))\n",
    "        mfcc = np.vstack([mfcc, pad])\n",
    "    else:\n",
    "        mfcc = mfcc[:max_frames]\n",
    "    return mfcc\n",
    "\n",
    "# ------------------------------\n",
    "# Inference function\n",
    "# ------------------------------\n",
    "def predict(video_path):\n",
    "    lips = extract_lip_landmarks(video_path)  # [150, 40]\n",
    "    audio = extract_audio_features(video_path)  # [150, 13]\n",
    "\n",
    "    lips_tensor = torch.tensor(lips, dtype=torch.float32).unsqueeze(0)   # [1, 150, 40]\n",
    "    audio_tensor = torch.tensor(audio, dtype=torch.float32).unsqueeze(0) # [1, 150, 13]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(lips_tensor, audio_tensor)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "        conf = probs[0, pred].item()\n",
    "        print(f\"Prediction: {'FAKE' if pred == 1 else 'REAL'} (Confidence: {conf:.2f})\")\n",
    "\n",
    "# ------------------------------\n",
    "# Run on a test video\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    test_video = \"fake/fake2.mp4\"  # Replace with your video path\n",
    "    predict(test_video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633531e7-c9fb-46c6-b756-6a2771d31a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hacksky)",
   "language": "python",
   "name": "hacksky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

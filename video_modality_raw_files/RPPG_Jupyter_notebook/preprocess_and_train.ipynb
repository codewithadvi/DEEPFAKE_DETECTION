{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca89bb98-11db-4f6d-a49c-9f7496a6b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Library ---\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- Third-party Libraries ---\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import mediapipe as mp\n",
    "\n",
    "# --- PyTorch ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56f0b7-3633-4647-95b0-723992c1662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_bvp_with_frames(bvp_trace, bvp_time, total_frames, fps):\n",
    "    \"\"\"\n",
    "    Resamples BVP to match video frame timestamps.\n",
    "    \"\"\"\n",
    "    frame_times = np.arange(total_frames) / fps\n",
    "    synced_bvp = np.interp(frame_times, bvp_time, bvp_trace)\n",
    "    return synced_bvp\n",
    "\n",
    "def process_video_mediapipe(video_path, bvp_path, save_dir, clip_len=150):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Load and sync BVP\n",
    "    bvp_raw = np.loadtxt(bvp_path)\n",
    "    if bvp_raw.ndim == 2:  # DATASET_2 format (3 x N)\n",
    "        bvp_trace = bvp_raw[0, :]\n",
    "        bvp_time = bvp_raw[2, :]  # seconds\n",
    "    else:  # Fallback if already 1D\n",
    "        bvp_trace = bvp_raw\n",
    "        bvp_time = np.arange(len(bvp_trace)) / fps\n",
    "\n",
    "    synced_bvp = sync_bvp_with_frames(bvp_trace, bvp_time, total_frames, fps)\n",
    "\n",
    "    frames, frame_idx, clip_idx = [], 0, 0\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.6) as face_detection:\n",
    "        with tqdm(total=total_frames, desc=f\"Processing {os.path.basename(save_dir)}\") as pbar:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = face_detection.process(rgb)\n",
    "\n",
    "                if results.detections:\n",
    "                    detection = results.detections[0]\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    h, w, _ = frame.shape\n",
    "                    x, y, bw, bh = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)\n",
    "                    x, y = max(0, x), max(0, y)\n",
    "                    face = frame[y:y+bh, x:x+bw]\n",
    "\n",
    "                    if face.size != 0:\n",
    "                        face = cv2.resize(face, (64, 64))\n",
    "                        frames.append(face)\n",
    "\n",
    "                # Save synced clips\n",
    "                if len(frames) == clip_len:\n",
    "                    clip_bvp = synced_bvp[frame_idx - clip_len + 1:frame_idx + 1]\n",
    "                    if len(clip_bvp) == clip_len:\n",
    "                        np.save(os.path.join(save_dir, f\"clip_{clip_idx}_frames.npy\"), np.array(frames))\n",
    "                        np.save(os.path.join(save_dir, f\"clip_{clip_idx}_bvp.npy\"), clip_bvp)\n",
    "                        clip_idx += 1\n",
    "                    frames = []\n",
    "\n",
    "                frame_idx += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"[INFO] Processed {clip_idx} clips from {video_path}\")\n",
    "\n",
    "def process_all_subjects(ubfc_dir, save_root=\"processed_data\"):\n",
    "    os.makedirs(save_root, exist_ok=True)\n",
    "    subjects = []\n",
    "    for s in os.listdir(ubfc_dir):\n",
    "        digits = ''.join(filter(str.isdigit, s))\n",
    "        if digits.isdigit():\n",
    "            subjects.append((s, int(digits)))\n",
    "    subjects = [s[0] for s in sorted(subjects, key=lambda x: x[1])]\n",
    "\n",
    "    for subj in subjects:\n",
    "        subj_path = os.path.join(ubfc_dir, subj)\n",
    "        if not os.path.isdir(subj_path):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(subj_path, \"vid.avi\")\n",
    "        bvp_path = os.path.join(subj_path, \"ground_truth.txt\")\n",
    "\n",
    "        if os.path.exists(video_path) and os.path.exists(bvp_path):\n",
    "            save_dir = os.path.join(save_root, subj)\n",
    "            process_video_mediapipe(video_path, bvp_path, save_dir)\n",
    "        else:\n",
    "            print(f\"[WARNING] Missing files for {subj}\")\n",
    "\n",
    "process_all_subjects(\"UBFC-RPPG\") #UBFC-RPPG dataset Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb7763-453f-47c8-96cf-f93cc981a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Loader\n",
    "class RPPGDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.samples = []\n",
    "        for subj in os.listdir(root):\n",
    "            subj_path = os.path.join(root, subj)\n",
    "            if os.path.isdir(subj_path):\n",
    "                frame_files = [f for f in os.listdir(subj_path) if \"frames\" in f]\n",
    "                for f in frame_files:\n",
    "                    frame_path = os.path.join(subj_path, f)\n",
    "                    bvp_path = frame_path.replace(\"frames\", \"bvp\")\n",
    "                    if os.path.exists(bvp_path):\n",
    "                        self.samples.append((frame_path, bvp_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frame_path, bvp_path = self.samples[idx]\n",
    "        frames = np.load(frame_path)          # (T, H, W, C) = (150, 64, 64, 3)\n",
    "        bvp = np.load(bvp_path)               # (T,)\n",
    "\n",
    "        frames = frames.transpose(3, 0, 1, 2) # ✅ Now (C, T, H, W)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32) / 255.0\n",
    "        bvp = torch.tensor(bvp, dtype=torch.float32)\n",
    "\n",
    "        return frames, bvp\n",
    "\n",
    "# Example usage:\n",
    "dataset = RPPGDataset(\"processed_data\")\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "print(f\"Total Clips: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead126d4-148f-4512-98ca-64fdb6a99673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D CNN PhysNET Definition\n",
    "class ConvBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1)):\n",
    "        super(ConvBlock3D, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "class ResidualBlock3D(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock3D, self).__init__()\n",
    "        self.conv1 = ConvBlock3D(channels, channels)\n",
    "        self.conv2 = ConvBlock3D(channels, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        return out + identity  # Skip connection\n",
    "\n",
    "\n",
    "class PhysNet3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PhysNet3D, self).__init__()\n",
    "        # Encoder\n",
    "        self.block1 = ConvBlock3D(3, 32, kernel_size=(3,5,5), stride=(1,1,1), padding=(1,2,2))\n",
    "        self.block2 = ConvBlock3D(32, 64, kernel_size=(3,5,5), stride=(1,2,2), padding=(1,2,2))\n",
    "        self.res2 = ResidualBlock3D(64)\n",
    "        self.block3 = ConvBlock3D(64, 128, kernel_size=(3,3,3), stride=(1,2,2), padding=(1,1,1))\n",
    "        self.res3 = ResidualBlock3D(128)\n",
    "        self.block4 = ConvBlock3D(128, 256, kernel_size=(3,3,3), stride=(1,2,2), padding=(1,1,1))\n",
    "        self.res4 = ResidualBlock3D(256)\n",
    "\n",
    "        # Decoder (Upsample to recover temporal resolution)\n",
    "        self.deconv3 = nn.ConvTranspose3d(256, 128, kernel_size=(1,4,4), stride=(1,2,2), padding=(0,1,1), output_padding=(0,0,0))\n",
    "        self.deconv2 = nn.ConvTranspose3d(128, 64, kernel_size=(1,4,4), stride=(1,2,2), padding=(0,1,1))\n",
    "        self.deconv1 = nn.ConvTranspose3d(64, 32, kernel_size=(1,4,4), stride=(1,2,2), padding=(0,1,1))\n",
    "\n",
    "        # Output: Predict 1-channel rPPG signal\n",
    "        self.out_conv = nn.Conv3d(32, 1, kernel_size=(1,1,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.block1(x)\n",
    "        x = self.res2(self.block2(x))\n",
    "        x = self.res3(self.block3(x))\n",
    "        x = self.res4(self.block4(x))\n",
    "\n",
    "        # Decoder\n",
    "        x = F.relu(self.deconv3(x))\n",
    "        x = F.relu(self.deconv2(x))\n",
    "        x = F.relu(self.deconv1(x))\n",
    "\n",
    "        x = self.out_conv(x)  # (B,1,T,H,W)\n",
    "        return x.mean(dim=[3,4])  # Average spatially → (B,1,T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197857d-7909-47ba-9de3-d305e0a599e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOSS FUNCTION\n",
    "def neg_pearson_loss(pred, target):\n",
    "    pred = pred.squeeze(1)\n",
    "    target = target.squeeze(1)\n",
    "\n",
    "    vx = pred - torch.mean(pred, dim=1, keepdim=True)\n",
    "    vy = target - torch.mean(target, dim=1, keepdim=True)\n",
    "\n",
    "    cost = torch.sum(vx * vy, dim=1) / (\n",
    "        torch.sqrt(torch.sum(vx**2, dim=1) * torch.sum(vy**2, dim=1)) + 1e-8\n",
    "    )\n",
    "    return 1 - cost.mean()  # 1 - Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f5307-5be3-4e5e-979d-762c71deac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training LOOP!\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = PhysNet3D().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = neg_pearson_loss  # Use Negative Pearson Loss\n",
    "\n",
    "EPOCHS = 15\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Wrap DataLoader with tqdm\n",
    "    pbar = tqdm(loader, desc=f\"Epoch [{epoch+1}/{EPOCHS}]\", unit=\"batch\")\n",
    "    \n",
    "    for frames, bvp in pbar:\n",
    "        frames, bvp = frames.to(device), bvp.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred = model(frames)  # (B,1,T)\n",
    "        loss = criterion(pred, bvp.unsqueeze(1))\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update TQDM bar with live loss\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Avg Loss: {running_loss/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7990cad5-98a7-4e5b-81fb-44b7b1106087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hacksky)",
   "language": "python",
   "name": "hacksky"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
